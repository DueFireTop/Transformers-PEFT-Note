{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer基本使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\work_tools\\Anaconda\\program\\envs\\my_transformers\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"弱小的我也有大梦想！\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 加载与保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从huggingface加载，输入模型名称，即可加载对应的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mf:\\Code\\MyTransformers\\1-Started\\2-tokenizer\\tokenizer.ipynb 单元格 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Code/MyTransformers/1-Started/2-tokenizer/tokenizer.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# tokenizer保存到本地\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Code/MyTransformers/1-Started/2-tokenizer/tokenizer.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tokenizer\u001b[39m.\u001b[39msave_pretrained(\u001b[39m\"\u001b[39m\u001b[39m./roberta_tokenizer\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# tokenizer保存到本地\n",
    "tokenizer.save_pretrained(\"./roberta_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从本地加载tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./roberta_tokenizer/\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 句子分词器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['弱', '小', '的', '我', '也', '有', '大', '梦', '想', '！']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sen)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 查看词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##蘇': 19036,\n",
       " '##貶': 19581,\n",
       " '##銭': 20131,\n",
       " '##unch': 11294,\n",
       " '》': 518,\n",
       " '0l': 10973,\n",
       " '##hm': 13130,\n",
       " '##膠': 18665,\n",
       " '355': 11753,\n",
       " '##獵': 17421,\n",
       " '##锢': 20292,\n",
       " '堿': 1845,\n",
       " '邨': 6931,\n",
       " '##蜜': 19114,\n",
       " '池': 3737,\n",
       " '靜': 7477,\n",
       " '##犁': 17355,\n",
       " '385': 11959,\n",
       " '##いた': 10526,\n",
       " 'angela': 12822,\n",
       " 'secret': 11634,\n",
       " '##咘': 14535,\n",
       " '319': 10865,\n",
       " '##71': 9097,\n",
       " '##62': 9290,\n",
       " '醉': 7004,\n",
       " '##这': 19878,\n",
       " '詡': 6272,\n",
       " '##40': 8660,\n",
       " '疇': 4539,\n",
       " 'coffee': 9706,\n",
       " '##邱': 19994,\n",
       " '莢': 5808,\n",
       " 'day2': 11144,\n",
       " '緣': 5225,\n",
       " '##340': 12149,\n",
       " '搪': 3020,\n",
       " '菀': 5820,\n",
       " 'って': 9127,\n",
       " '饕': 7642,\n",
       " 'super': 8988,\n",
       " '訴': 6260,\n",
       " '##墩': 14932,\n",
       " '##奔': 15001,\n",
       " '萵': 5859,\n",
       " '矩': 4762,\n",
       " '瀏': 4104,\n",
       " '##徘': 15591,\n",
       " 'sdk': 10302,\n",
       " '260': 9044,\n",
       " '◇': 471,\n",
       " '锁': 7219,\n",
       " '426': 12408,\n",
       " '##×': 9569,\n",
       " '##泳': 16864,\n",
       " '涇': 3866,\n",
       " '##ⅱ': 13520,\n",
       " '淫': 3915,\n",
       " 'ocean': 12546,\n",
       " '##てお': 12878,\n",
       " '士': 1894,\n",
       " 'most': 11344,\n",
       " '絹': 5191,\n",
       " '嚟': 1708,\n",
       " '##佐': 13915,\n",
       " '##耽': 18517,\n",
       " '##薇': 19005,\n",
       " '##餮': 20689,\n",
       " '摆': 3030,\n",
       " '##吡': 14471,\n",
       " '##嘶': 14731,\n",
       " '凱': 1134,\n",
       " 'tvg': 12547,\n",
       " '##med': 13089,\n",
       " '曄': 3277,\n",
       " '験': 7699,\n",
       " '##兲': 14124,\n",
       " '##付': 13859,\n",
       " '##煖': 17262,\n",
       " 'ᄋ': 297,\n",
       " '消': 3867,\n",
       " '卑': 1292,\n",
       " '恵': 2625,\n",
       " 'press': 9228,\n",
       " '##ary': 9277,\n",
       " '625': 12218,\n",
       " '##ᄋ': 13463,\n",
       " '##妾': 15046,\n",
       " '##舷': 18725,\n",
       " '##鉚': 20117,\n",
       " '##鸞': 20937,\n",
       " '##雳': 20495,\n",
       " '##嗽': 14701,\n",
       " 'series': 10976,\n",
       " '懑': 2749,\n",
       " '##证': 19452,\n",
       " '往': 2518,\n",
       " '##ょ': 13677,\n",
       " '氫': 3712,\n",
       " 'ap': 9392,\n",
       " '##笠': 18072,\n",
       " '囗': 1722,\n",
       " '贊': 6558,\n",
       " '５': 8033,\n",
       " '##｀': 21094,\n",
       " '##锄': 20278,\n",
       " '##】': 13659,\n",
       " '溟': 3979,\n",
       " 'めて': 11967,\n",
       " '[unused47]': 47,\n",
       " '胄': 5518,\n",
       " '隴': 7404,\n",
       " '##c': 8177,\n",
       " '##偵': 14037,\n",
       " '##析': 16415,\n",
       " '##负': 19623,\n",
       " '胡': 5529,\n",
       " '##徹': 15606,\n",
       " '缀': 5345,\n",
       " 'チ': 609,\n",
       " '##bert': 10491,\n",
       " '##円': 14137,\n",
       " '堪': 1838,\n",
       " '156': 9508,\n",
       " '缱': 5372,\n",
       " '##喚': 14655,\n",
       " '##釉': 20081,\n",
       " '纨': 5278,\n",
       " '##เ': 13450,\n",
       " '1944': 9462,\n",
       " '##❀': 13641,\n",
       " 'スキル': 11862,\n",
       " '##呦': 14509,\n",
       " '##07': 9131,\n",
       " '##きました': 12055,\n",
       " '1999': 8338,\n",
       " '##較': 19790,\n",
       " '装': 6163,\n",
       " '1981': 8785,\n",
       " '##外': 14969,\n",
       " '##谘': 19519,\n",
       " '餉': 7620,\n",
       " '##佻': 13941,\n",
       " '##蕁': 18987,\n",
       " '##遊': 19936,\n",
       " '仍': 793,\n",
       " 'sunday': 11548,\n",
       " '底': 2419,\n",
       " '佳': 881,\n",
       " '妞': 1977,\n",
       " '31': 8176,\n",
       " '##許': 19315,\n",
       " '##阔': 20390,\n",
       " '[unused74]': 74,\n",
       " 'eur': 11991,\n",
       " '##45': 9039,\n",
       " '##凳': 14192,\n",
       " '鸯': 7891,\n",
       " '萧': 5854,\n",
       " '##瑩': 17510,\n",
       " '蹼': 6706,\n",
       " '麋': 7924,\n",
       " '##詰': 19338,\n",
       " '莪': 5810,\n",
       " '##ok': 9185,\n",
       " '褥': 6191,\n",
       " '##毆': 16733,\n",
       " '##罡': 18443,\n",
       " '带': 2372,\n",
       " '弟': 2475,\n",
       " '120': 8290,\n",
       " '頃': 7516,\n",
       " 'national': 9385,\n",
       " '锯': 7242,\n",
       " '##port': 9356,\n",
       " '##室': 15204,\n",
       " '##р': 13415,\n",
       " '##⒈': 13571,\n",
       " '##芎': 18751,\n",
       " '##薏': 19008,\n",
       " '##雁': 20469,\n",
       " '##る': 8481,\n",
       " '繼': 5262,\n",
       " '覃': 6207,\n",
       " '##ｏ': 9940,\n",
       " '##顛': 20602,\n",
       " '閾': 7292,\n",
       " '掸': 2981,\n",
       " '个': 702,\n",
       " '音': 7509,\n",
       " 'win10': 8634,\n",
       " '##胛': 18582,\n",
       " '努': 1222,\n",
       " '52sykb': 12846,\n",
       " '##谩': 19532,\n",
       " 'herme': 8834,\n",
       " '##蛔': 19088,\n",
       " '##point': 11112,\n",
       " '##總': 18301,\n",
       " '嘖': 1654,\n",
       " '蘚': 5983,\n",
       " '##ha': 8778,\n",
       " '##hr': 10561,\n",
       " '桐': 3432,\n",
       " '衙': 6126,\n",
       " '伶': 846,\n",
       " '駿': 7695,\n",
       " '##控': 16028,\n",
       " '1600': 8903,\n",
       " '##苒': 18781,\n",
       " '赢': 6617,\n",
       " '##蝴': 19135,\n",
       " 'block': 10188,\n",
       " '##鬣': 20840,\n",
       " '##踞': 19732,\n",
       " '##擇': 16136,\n",
       " '[unused48]': 48,\n",
       " '##沫': 16830,\n",
       " '##fu': 12043,\n",
       " '##击': 14197,\n",
       " '##帽': 15441,\n",
       " 'ta': 8346,\n",
       " '##亀': 13804,\n",
       " 'place': 10963,\n",
       " '##喂': 14642,\n",
       " '##苻': 18799,\n",
       " '荨': 5787,\n",
       " '儷': 1034,\n",
       " '﹝': 8009,\n",
       " 'gd': 11729,\n",
       " '##熨': 17284,\n",
       " '渙': 3936,\n",
       " '汁': 3723,\n",
       " '部': 6956,\n",
       " '冥': 1097,\n",
       " '囤': 1732,\n",
       " '靴': 7486,\n",
       " '##筛': 18090,\n",
       " '瘠': 4603,\n",
       " '庆': 2412,\n",
       " '輿': 6748,\n",
       " '##110': 12518,\n",
       " '种': 4905,\n",
       " '昶': 3225,\n",
       " '病': 4567,\n",
       " '侮': 907,\n",
       " '该': 6421,\n",
       " '##kins': 13084,\n",
       " '肥': 5503,\n",
       " '##扑': 15857,\n",
       " '##晷': 16311,\n",
       " '371': 12584,\n",
       " '球': 4413,\n",
       " '##贬': 19635,\n",
       " '##遛': 19949,\n",
       " '##臆': 18678,\n",
       " 'error': 10812,\n",
       " '誹': 6308,\n",
       " '铄': 7191,\n",
       " '蓿': 5911,\n",
       " '窒': 4966,\n",
       " '咁': 1464,\n",
       " '##暉': 16318,\n",
       " '寢': 2177,\n",
       " '5t': 12204,\n",
       " 'a1': 9454,\n",
       " '溅': 3972,\n",
       " '1961': 9199,\n",
       " '##惚': 15723,\n",
       " '铠': 7200,\n",
       " '154': 9220,\n",
       " '尼': 2225,\n",
       " '##売': 14956,\n",
       " '##忖': 15618,\n",
       " '僵': 1018,\n",
       " '傅': 987,\n",
       " '1998': 8368,\n",
       " '##▫': 13608,\n",
       " '蹙': 6694,\n",
       " '##潴': 17119,\n",
       " '##berg': 10039,\n",
       " '##ｔ': 11766,\n",
       " '##晌': 16290,\n",
       " '1922': 10209,\n",
       " 'κ': 218,\n",
       " 'wong': 11615,\n",
       " '##碑': 17868,\n",
       " '案': 3428,\n",
       " '莊': 5800,\n",
       " '##筲': 18094,\n",
       " '##镉': 20310,\n",
       " '極': 3513,\n",
       " '##淘': 16962,\n",
       " '##麼': 20995,\n",
       " 'sofascore': 11555,\n",
       " '遐': 6884,\n",
       " '##棚': 16533,\n",
       " '蒋': 5882,\n",
       " '##洹': 16889,\n",
       " '薅': 5947,\n",
       " '##有': 16357,\n",
       " '犒': 4302,\n",
       " '##姒': 15054,\n",
       " '卮': 1311,\n",
       " '##私': 17957,\n",
       " '鑣': 7143,\n",
       " '##貧': 19571,\n",
       " '##﹑': 21058,\n",
       " '##令': 13865,\n",
       " 'hit': 10295,\n",
       " '##寓': 15228,\n",
       " '##賂': 19590,\n",
       " '##个': 13759,\n",
       " '##伙': 13889,\n",
       " '##积': 17973,\n",
       " '##繩': 18313,\n",
       " '##衛': 19184,\n",
       " '##＇': 21076,\n",
       " '##？': 21087,\n",
       " '##ral': 10482,\n",
       " '##喱': 14665,\n",
       " '##蝗': 19129,\n",
       " '粹': 5122,\n",
       " '##ータ': 12219,\n",
       " 'insee': 11513,\n",
       " '##霊': 20508,\n",
       " '摯': 3041,\n",
       " '闊': 7295,\n",
       " '##ย': 13446,\n",
       " 'vogue': 10137,\n",
       " '##潇': 17102,\n",
       " '##徳': 15602,\n",
       " '##歼': 16705,\n",
       " '訣': 6254,\n",
       " 'zone': 11957,\n",
       " '##鬥': 20841,\n",
       " '##sson': 12582,\n",
       " '##猗': 17393,\n",
       " '瞇': 4732,\n",
       " '##舂': 18699,\n",
       " '##革': 20541,\n",
       " '##host': 12227,\n",
       " '嗬': 1637,\n",
       " '潢': 4055,\n",
       " '1966': 9093,\n",
       " 'gt': 9046,\n",
       " '遲': 6903,\n",
       " 'します': 8845,\n",
       " '遂': 6876,\n",
       " '##瘧': 17665,\n",
       " 'ن': 271,\n",
       " '##ions': 11137,\n",
       " '[unused56]': 56,\n",
       " '売': 1899,\n",
       " '酐': 6982,\n",
       " '雕': 7425,\n",
       " '1a': 11942,\n",
       " '##铭': 20265,\n",
       " '##绷': 18395,\n",
       " '啷': 1579,\n",
       " '矛': 4757,\n",
       " 'з': 240,\n",
       " '拔': 2869,\n",
       " 'von': 12310,\n",
       " '##銃': 20123,\n",
       " '黠': 7954,\n",
       " 'se': 9342,\n",
       " '##脘': 18614,\n",
       " '##灿': 17193,\n",
       " '##襟': 19256,\n",
       " '打': 2802,\n",
       " '揄': 2985,\n",
       " '瀰': 4116,\n",
       " '##唳': 14606,\n",
       " '我': 2769,\n",
       " '##ip': 9032,\n",
       " '霹': 7465,\n",
       " '##聲': 18533,\n",
       " '##贩': 19632,\n",
       " '##敘': 16192,\n",
       " '##º': 13358,\n",
       " '##ᅴ': 13483,\n",
       " '屈': 2235,\n",
       " '瀆': 4101,\n",
       " '矢': 4759,\n",
       " '丕': 685,\n",
       " '##味': 14513,\n",
       " '謐': 6337,\n",
       " '##商': 14612,\n",
       " '##摆': 16087,\n",
       " '[unused45]': 45,\n",
       " '##来': 16398,\n",
       " '##bow': 12559,\n",
       " '292': 11542,\n",
       " '##氹': 16777,\n",
       " '##邑': 19980,\n",
       " '监': 4664,\n",
       " '淆': 3898,\n",
       " '##僱': 14074,\n",
       " '葭': 5874,\n",
       " '紐': 5153,\n",
       " '##orage': 12669,\n",
       " '##転': 19785,\n",
       " 'kk': 11923,\n",
       " '踝': 6674,\n",
       " '烧': 4173,\n",
       " '001': 9263,\n",
       " '##勐': 14295,\n",
       " '##宅': 15182,\n",
       " 'alt': 9721,\n",
       " '##驚': 20768,\n",
       " '戒': 2770,\n",
       " '八': 1061,\n",
       " '熾': 4232,\n",
       " '隕': 7393,\n",
       " '殞': 3660,\n",
       " '##張': 15541,\n",
       " '##蝼': 19138,\n",
       " '##閔': 20337,\n",
       " '冪': 1099,\n",
       " '□': 460,\n",
       " 'am': 8413,\n",
       " '211': 9395,\n",
       " '｢': 8082,\n",
       " '##远': 19880,\n",
       " '##煌': 17259,\n",
       " '##ة': 13429,\n",
       " '##沦': 16827,\n",
       " '##揍': 16045,\n",
       " 'yy': 9453,\n",
       " '頼': 7537,\n",
       " '瘟': 4602,\n",
       " 'ｅ': 8055,\n",
       " '##種': 17991,\n",
       " '犢': 4303,\n",
       " '##倬': 14019,\n",
       " '芳': 5710,\n",
       " 'if': 8898,\n",
       " '间': 7313,\n",
       " '##匈': 14318,\n",
       " '躲': 6719,\n",
       " '##rcle': 12466,\n",
       " '##枯': 16426,\n",
       " '润': 3883,\n",
       " '##羿': 18475,\n",
       " '從': 2537,\n",
       " 'ⅲ': 365,\n",
       " '陽': 7382,\n",
       " 'cad': 8645,\n",
       " '##mix': 11091,\n",
       " '告': 1440,\n",
       " '續': 5265,\n",
       " '##嶋': 15382,\n",
       " '##挲': 15978,\n",
       " '##採': 16024,\n",
       " 'ㄇ': 649,\n",
       " 'liu': 12306,\n",
       " '聶': 5479,\n",
       " '##い': 8524,\n",
       " '勁': 1233,\n",
       " '貯': 6520,\n",
       " '滇': 3995,\n",
       " 'watch': 9114,\n",
       " 'tcp': 9901,\n",
       " '##ws': 10402,\n",
       " 'v5': 11133,\n",
       " 'tft': 12177,\n",
       " '##伶': 13903,\n",
       " '勞': 1246,\n",
       " '擲': 3096,\n",
       " '攝': 3109,\n",
       " '##蜻': 19121,\n",
       " '嬿': 2091,\n",
       " '##製': 19239,\n",
       " '##趋': 19690,\n",
       " '##ect': 10862,\n",
       " '##68': 9105,\n",
       " '##蘆': 19035,\n",
       " '##滙': 17059,\n",
       " '##庞': 15482,\n",
       " '##闰': 20368,\n",
       " '稹': 4939,\n",
       " '隼': 7408,\n",
       " '##讳': 19440,\n",
       " '##題': 20596,\n",
       " 'itunes': 9041,\n",
       " '︰': 7992,\n",
       " '咆': 1467,\n",
       " '##崁': 15354,\n",
       " '##细': 18358,\n",
       " 'pchome': 9780,\n",
       " '##踪': 19736,\n",
       " '某': 3378,\n",
       " '炙': 4147,\n",
       " '宅': 2125,\n",
       " '##瑪': 17511,\n",
       " '##质': 19631,\n",
       " '暝': 3267,\n",
       " 'wali': 10736,\n",
       " '碣': 4818,\n",
       " '##ック': 9244,\n",
       " '嘜': 1659,\n",
       " '驛': 7712,\n",
       " '##oz': 13102,\n",
       " '##馁': 20721,\n",
       " '##轆': 19808,\n",
       " '##掺': 16039,\n",
       " '##托': 15862,\n",
       " '##yi': 11017,\n",
       " '##俨': 13986,\n",
       " 'lo': 12264,\n",
       " '盟': 4673,\n",
       " '悌': 2635,\n",
       " '粳': 5120,\n",
       " '##ш': 13423,\n",
       " '##津': 16880,\n",
       " '✈': 496,\n",
       " 'みてす': 11870,\n",
       " '尧': 2216,\n",
       " '##勝': 14302,\n",
       " '##梆': 16507,\n",
       " '##揉': 16044,\n",
       " '##然': 17254,\n",
       " '##侷': 13968,\n",
       " '瞅': 4731,\n",
       " '##军': 14149,\n",
       " '950': 10468,\n",
       " '愚': 2694,\n",
       " '苁': 5717,\n",
       " '醍': 7006,\n",
       " '##do': 8828,\n",
       " 'qi': 11566,\n",
       " '##蠔': 19163,\n",
       " '##钢': 20224,\n",
       " '瞭': 4747,\n",
       " '##捕': 15993,\n",
       " 'williams': 11475,\n",
       " '##裟': 19230,\n",
       " '##※': 13508,\n",
       " '##腊': 18629,\n",
       " '##イフ': 12692,\n",
       " '练': 5298,\n",
       " '97': 8380,\n",
       " '##韵': 20567,\n",
       " '##;': 13333,\n",
       " '##咏': 14528,\n",
       " '##耦': 18510,\n",
       " 'ᅲ': 317,\n",
       " 'wow': 11607,\n",
       " '蠱': 6113,\n",
       " '##篡': 18127,\n",
       " '##卤': 14364,\n",
       " '##承': 15881,\n",
       " '##鍛': 20161,\n",
       " '篑': 5065,\n",
       " 'sso': 11499,\n",
       " 'いて': 11232,\n",
       " '##≥': 13546,\n",
       " '##軸': 19786,\n",
       " '穗': 4950,\n",
       " '邁': 6914,\n",
       " '鍥': 7105,\n",
       " 'xuite': 13194,\n",
       " '耶': 5456,\n",
       " '4g': 8340,\n",
       " '鮮': 7804,\n",
       " '訂': 6242,\n",
       " 'c1': 10905,\n",
       " 'supreme': 11272,\n",
       " '##bank': 10980,\n",
       " '##other': 11759,\n",
       " '児': 1049,\n",
       " '蝼': 6081,\n",
       " 'lte': 8987,\n",
       " '枫': 3367,\n",
       " '##仑': 13853,\n",
       " 'coc': 11917,\n",
       " '脇': 5547,\n",
       " '剣': 1193,\n",
       " '##鞭': 20555,\n",
       " '##心': 15609,\n",
       " '條': 3454,\n",
       " '▫': 462,\n",
       " 'standard': 12038,\n",
       " '娩': 2030,\n",
       " '##梗': 16510,\n",
       " '憐': 2730,\n",
       " '胜': 5526,\n",
       " '汇': 3726,\n",
       " '##煙': 17263,\n",
       " '雀': 7411,\n",
       " 'etnews': 12870,\n",
       " '轴': 6766,\n",
       " '##劝': 14271,\n",
       " '##櫸': 16663,\n",
       " 'cambridge': 11788,\n",
       " '##о': 13413,\n",
       " '##嘈': 14705,\n",
       " '##黏': 21002,\n",
       " '##uel': 11866,\n",
       " '長': 7269,\n",
       " '##譏': 19408,\n",
       " 'м': 244,\n",
       " '##滔': 17057,\n",
       " '茗': 5751,\n",
       " '呀': 1435,\n",
       " '㗎': 670,\n",
       " '兮': 1064,\n",
       " '暨': 3270,\n",
       " '沫': 3773,\n",
       " '##ng': 8291,\n",
       " '##璋': 17521,\n",
       " '砚': 4780,\n",
       " '##琮': 17486,\n",
       " '107': 8632,\n",
       " '窦': 4977,\n",
       " '碱': 4822,\n",
       " '##哈': 14563,\n",
       " '漲': 4039,\n",
       " '##慑': 15766,\n",
       " '滸': 4019,\n",
       " '##怖': 15644,\n",
       " '##没': 16823,\n",
       " '##駅': 20743,\n",
       " '傭': 999,\n",
       " '衄': 6118,\n",
       " '##万': 13731,\n",
       " '##诊': 19459,\n",
       " '##颌': 20628,\n",
       " '狼': 4331,\n",
       " '##玮': 17440,\n",
       " '丝': 692,\n",
       " 'time': 8759,\n",
       " 'icecat': 9336,\n",
       " '##讪': 19433,\n",
       " '##涯': 16946,\n",
       " '##軟': 19784,\n",
       " '舟': 5660,\n",
       " 'git': 10807,\n",
       " '##なら': 10145,\n",
       " '##陣': 20426,\n",
       " '##恪': 15675,\n",
       " '##蜷': 19120,\n",
       " '皺': 4653,\n",
       " '##灶': 17188,\n",
       " '##窥': 18033,\n",
       " '##门': 20362,\n",
       " '##油': 16836,\n",
       " '##月': 16356,\n",
       " '類': 7546,\n",
       " '##頤': 20586,\n",
       " '鎊': 7111,\n",
       " 'hall': 11049,\n",
       " 'road': 9772,\n",
       " '##由': 17564,\n",
       " '239': 10694,\n",
       " '##浪': 16914,\n",
       " '##赦': 19677,\n",
       " '##閣': 20341,\n",
       " '##檻': 16658,\n",
       " '百': 4636,\n",
       " '##her': 9856,\n",
       " '278': 11191,\n",
       " '##竟': 18051,\n",
       " 'worldcat': 10698,\n",
       " '##ㄉ': 13708,\n",
       " '声': 1898,\n",
       " '##泯': 16861,\n",
       " 'maria': 12096,\n",
       " '##寥': 15235,\n",
       " '##ａ': 10094,\n",
       " '##脸': 18624,\n",
       " '##樫': 16624,\n",
       " '榖': 3526,\n",
       " '##ら': 8732,\n",
       " '遠': 6895,\n",
       " '繁': 5246,\n",
       " 'flash': 8427,\n",
       " '##駛': 20748,\n",
       " '##籟': 18152,\n",
       " '##堙': 14892,\n",
       " '简': 5042,\n",
       " 'ua': 11107,\n",
       " '紫': 5166,\n",
       " '##妹': 15044,\n",
       " '##気': 16757,\n",
       " '21': 8128,\n",
       " '尸': 2221,\n",
       " '##咫': 14546,\n",
       " '搖': 3015,\n",
       " '##眼': 17763,\n",
       " '嚇': 1702,\n",
       " '個': 943,\n",
       " '霰': 7462,\n",
       " '##楊': 16558,\n",
       " '##甚': 17550,\n",
       " '誅': 6287,\n",
       " '600': 8298,\n",
       " '##尖': 15268,\n",
       " '买': 743,\n",
       " '癸': 4631,\n",
       " 'わせ': 11878,\n",
       " '##ito': 12899,\n",
       " '##怡': 15649,\n",
       " '##箝': 18108,\n",
       " '♫': 494,\n",
       " '序': 2415,\n",
       " 'der': 9157,\n",
       " '##fe': 9568,\n",
       " '##墊': 14922,\n",
       " '##十': 14339,\n",
       " '單': 1606,\n",
       " '嶄': 2323,\n",
       " '犬': 4305,\n",
       " '龜': 7990,\n",
       " 'html': 8304,\n",
       " 'exhibition': 13282,\n",
       " '轉': 6752,\n",
       " '##察': 15232,\n",
       " 'qualcomm': 13264,\n",
       " '##痢': 17638,\n",
       " '##架': 16430,\n",
       " '##vertisement': 12021,\n",
       " '吋': 1397,\n",
       " '##俠': 13984,\n",
       " '##签': 18098,\n",
       " '##猫': 17401,\n",
       " '##允': 14095,\n",
       " '播': 3064,\n",
       " '##頗': 20582,\n",
       " '━': 428,\n",
       " '谴': 6482,\n",
       " '転': 6728,\n",
       " '34e': 11614,\n",
       " '##繇': 18306,\n",
       " '##麸': 20992,\n",
       " '##关': 14125,\n",
       " 'の': 561,\n",
       " '荳': 5791,\n",
       " '輛': 6739,\n",
       " 'ㄛ': 658,\n",
       " '钟': 7164,\n",
       " '攸': 3120,\n",
       " 'その': 8782,\n",
       " '##16': 8518,\n",
       " 'open': 8893,\n",
       " '##阎': 20387,\n",
       " '430': 10352,\n",
       " '##法': 16848,\n",
       " 'dram': 10664,\n",
       " '唾': 1552,\n",
       " '挞': 2910,\n",
       " '415': 12114,\n",
       " '##佯': 13936,\n",
       " 'admin': 8843,\n",
       " '##羞': 18461,\n",
       " '坍': 1774,\n",
       " '稽': 4942,\n",
       " '砂': 4773,\n",
       " '阐': 7331,\n",
       " '##帛': 15425,\n",
       " '##涧': 16941,\n",
       " '栓': 3410,\n",
       " '##砼': 17849,\n",
       " '咩': 1487,\n",
       " '愍': 2691,\n",
       " '披': 2847,\n",
       " '楫': 3510,\n",
       " '##渦': 17002,\n",
       " 'β': 211,\n",
       " '鑄': 7139,\n",
       " '##猿': 17408,\n",
       " '##髏': 20822,\n",
       " '閒': 7278,\n",
       " '嵌': 2316,\n",
       " 'content': 9432,\n",
       " '圾': 1769,\n",
       " '##唉': 14593,\n",
       " '##增': 14929,\n",
       " '牯': 4290,\n",
       " 'topapp': 10607,\n",
       " '##。': 13646,\n",
       " '篝': 5068,\n",
       " '##手': 15854,\n",
       " '卞': 1302,\n",
       " '##沓': 16818,\n",
       " 'aa': 9563,\n",
       " '##卷': 14375,\n",
       " '##岩': 15329,\n",
       " 'シ': 604,\n",
       " '够': 1916,\n",
       " '腩': 5583,\n",
       " '缙': 5358,\n",
       " '##tty': 11160,\n",
       " '##縄': 18291,\n",
       " '##而': 18502,\n",
       " '##✈': 13632,\n",
       " '闲': 7312,\n",
       " 'cr': 10951,\n",
       " '徉': 2524,\n",
       " 'on': 8281,\n",
       " '⒈': 420,\n",
       " '娲': 2032,\n",
       " '花': 5709,\n",
       " '邦': 6930,\n",
       " '哐': 1513,\n",
       " '遁': 6875,\n",
       " '##报': 15902,\n",
       " '賺': 6553,\n",
       " '##板': 16409,\n",
       " '##犄': 17356,\n",
       " '##至': 18692,\n",
       " '##醍': 20063,\n",
       " '##破': 17845,\n",
       " '364': 12673,\n",
       " '3～4': 12907,\n",
       " '胰': 5536,\n",
       " '椪': 3494,\n",
       " '##毒': 16738,\n",
       " '止': 3632,\n",
       " '##鹃': 20955,\n",
       " '矣': 4760,\n",
       " '1950': 8707,\n",
       " '##滨': 17069,\n",
       " '咔': 1474,\n",
       " '怔': 2585,\n",
       " '[unused97]': 97,\n",
       " '拦': 2882,\n",
       " '珠': 4403,\n",
       " '琴': 4433,\n",
       " '##搁': 16064,\n",
       " '##ost': 12085,\n",
       " '槟': 3547,\n",
       " '檀': 3589,\n",
       " '850': 10205,\n",
       " '##匱': 14332,\n",
       " '##篁': 18117,\n",
       " '酬': 6992,\n",
       " '锚': 7232,\n",
       " '##倆': 13998,\n",
       " '34': 8229,\n",
       " '受': 1358,\n",
       " 'apr': 9011,\n",
       " '##sol': 12257,\n",
       " '##鯖': 20864,\n",
       " '##♦': 13629,\n",
       " '##ek': 9534,\n",
       " '##倌': 14001,\n",
       " '##ther': 10198,\n",
       " 'http': 8184,\n",
       " '##曬': 16344,\n",
       " '唆': 1534,\n",
       " '##润': 16940,\n",
       " '[unused33]': 33,\n",
       " '鈪': 7050,\n",
       " '##ント': 10002,\n",
       " '##撞': 16115,\n",
       " '鎮': 7120,\n",
       " '熏': 4221,\n",
       " '戬': 2780,\n",
       " '##蛾': 19099,\n",
       " 'について': 10779,\n",
       " 'hero': 11673,\n",
       " '##ean': 10096,\n",
       " '##琴': 17490,\n",
       " '##k': 8197,\n",
       " '##仗': 13858,\n",
       " '擬': 3093,\n",
       " 'magic': 10328,\n",
       " '絡': 5181,\n",
       " '密': 2166,\n",
       " '寞': 2174,\n",
       " 'p10': 10405,\n",
       " '檎': 3591,\n",
       " '##迷': 19894,\n",
       " '##間': 20336,\n",
       " '##勘': 14299,\n",
       " '##涮': 16945,\n",
       " '##fi': 9864,\n",
       " '##易': 16268,\n",
       " '厮': 1340,\n",
       " '##櫻': 16664,\n",
       " '##ement': 11946,\n",
       " '##zon': 10623,\n",
       " '宙': 2136,\n",
       " '請': 6313,\n",
       " '跳': 6663,\n",
       " '##mbps': 12399,\n",
       " '##揽': 16062,\n",
       " '##槌': 16597,\n",
       " '锂': 7220,\n",
       " '鉗': 7059,\n",
       " '32g': 13181,\n",
       " '##測': 17004,\n",
       " '属': 2247,\n",
       " '赶': 6628,\n",
       " '6l': 12061,\n",
       " '##鑒': 20199,\n",
       " '枸': 3375,\n",
       " '臨': 5631,\n",
       " '鎬': 7119,\n",
       " '蝕': 6071,\n",
       " 'nikon': 11391,\n",
       " 'bean': 13188,\n",
       " '##泵': 16865,\n",
       " '##碉': 17864,\n",
       " '##偈': 14027,\n",
       " '##蜈': 19105,\n",
       " 'る': 580,\n",
       " 'ㄨ': 665,\n",
       " '诏': 6405,\n",
       " '##血': 19174,\n",
       " '##冨': 14155,\n",
       " '輾': 6747,\n",
       " '##ㄇ': 13707,\n",
       " '##暴': 16331,\n",
       " 'xuehai': 10528,\n",
       " '系': 5143,\n",
       " '801': 12566,\n",
       " '◤': 478,\n",
       " 'ς': 225,\n",
       " '##nts': 12585,\n",
       " '##冠': 14151,\n",
       " '囍': 1719,\n",
       " '輻': 6746,\n",
       " '##af': 11472,\n",
       " 'puma': 11803,\n",
       " '蘿': 5987,\n",
       " 'left': 12744,\n",
       " '##eting': 13216,\n",
       " '##we': 11722,\n",
       " '##憲': 15797,\n",
       " '試': 6275,\n",
       " '##lon': 10146,\n",
       " '##夜': 14972,\n",
       " 'king': 9382,\n",
       " '##鈺': 20109,\n",
       " '##醉': 20061,\n",
       " '##ん': 8814,\n",
       " '猬': 4345,\n",
       " '##币': 15412,\n",
       " '##缙': 18415,\n",
       " '##嫂': 15121,\n",
       " 'hotmail': 10728,\n",
       " '辄': 6773,\n",
       " '##せ': 10452,\n",
       " '崧': 2308,\n",
       " '##δ': 13383,\n",
       " '##堯': 14896,\n",
       " '##霾': 20524,\n",
       " 'rn': 11998,\n",
       " 'richard': 9875,\n",
       " '校': 3413,\n",
       " '##冻': 14165,\n",
       " '姝': 2003,\n",
       " '##拦': 15939,\n",
       " '##橢': 16641,\n",
       " '骰': 7757,\n",
       " '塘': 1851,\n",
       " '国': 1744,\n",
       " 'request': 12931,\n",
       " '##莲': 18870,\n",
       " '〈': 515,\n",
       " '慕': 2710,\n",
       " '##阡': 20397,\n",
       " '863': 12874,\n",
       " '∀': 376,\n",
       " '##泥': 16856,\n",
       " '是': 3221,\n",
       " '戴': 2785,\n",
       " '##喟': 14658,\n",
       " '##臼': 18696,\n",
       " '##殃': 16707,\n",
       " '888': 9389,\n",
       " '##帥': 15428,\n",
       " '英': 5739,\n",
       " '##买': 13800,\n",
       " '坠': 1785,\n",
       " '魄': 7790,\n",
       " '刘': 1155,\n",
       " '摊': 3033,\n",
       " 'out': 8883,\n",
       " '##糰': 18198,\n",
       " '硼': 4804,\n",
       " 'tai': 13242,\n",
       " '##奐': 14999,\n",
       " '菅': 5822,\n",
       " 'river': 10835,\n",
       " '##怆': 15638,\n",
       " '隙': 7395,\n",
       " '##攥': 16171,\n",
       " '##偷': 14039,\n",
       " '##ss': 8565,\n",
       " '鉤': 7062,\n",
       " '箇': 5043,\n",
       " '##ا': 13427,\n",
       " '##峨': 15345,\n",
       " '##ける': 11760,\n",
       " '##傩': 14054,\n",
       " '##奋': 14996,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 词表的大小\n",
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 索引转换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 8013]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将词序列转换为id序列\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['弱', '小', '的', '我', '也', '有', '大', '梦', '想', '！']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将id序列转换为token序列\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'弱 小 的 我 也 有 大 梦 想 ！'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将token序列转换为string\n",
    "str_sen = tokenizer.convert_tokens_to_string(tokens)\n",
    "str_sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 更便捷的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 8013, 102]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将字符串转换为id序列，又称为编码\n",
    "# add_special_tokens 是否添加特殊token\n",
    "ids = tokenizer.encode(sen)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 8013]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(sen, add_special_tokens=False)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'弱 小 的 我 也 有 大 梦 想 ！'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将id序列转换为字符串，又称为解码\n",
    "# skip_special_tokens 是否跳过特殊token\n",
    "str_sen = tokenizer.decode(ids, skip_special_tokens=True)\n",
    "str_sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] 弱 小 的 我 也 有 大 梦 想 ！ [SEP]'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_sen = tokenizer.decode(ids, skip_special_tokens=False)\n",
    "str_sen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 填充与截断"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 8013, 102, 0, 0, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 填充\n",
    "ids = tokenizer.encode(sen,add_special_tokens=True, padding=\"max_length\", max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2483, 2207, 4638, 2769, 738]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 截断 truncation=True\n",
    "ids = tokenizer.encode(sen, add_special_tokens=False, max_length=5, truncation=True)\n",
    "ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 其他输入部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 8013, 102, 0, 0, 0]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(sen,add_special_tokens=True, padding=\"max_length\", max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101,\n",
       "  2483,\n",
       "  2207,\n",
       "  4638,\n",
       "  2769,\n",
       "  738,\n",
       "  3300,\n",
       "  1920,\n",
       "  3457,\n",
       "  2682,\n",
       "  8013,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = [1 if idx != 0 else 0 for idx in ids]\n",
    "token_type_ids = [0] * len(ids) # 标记是第几个句子\n",
    "ids, attention_mask, token_type_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 快速调用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 8013, 102, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode_plus(sen, padding=\"max_length\", max_length=15, add_special_tokens=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 8013, 102, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sen, padding=\"max_length\", max_length=15, add_special_tokens=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 处理batch数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102], [101, 3300, 3457, 2682, 6443, 738, 749, 679, 6629, 102], [101, 6841, 6852, 3457, 2682, 4638, 2552, 8024, 3683, 3457, 2682, 3315, 6716, 3291, 1377, 6586, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens = [\"弱小的我也有大梦想\",\n",
    "        \"有梦想谁也了不起\",\n",
    "        \"追逐梦想的心，比梦想本身更可贵\"]\n",
    "\n",
    "res = tokenizer(sens)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"弱小的我也有大梦想！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 62.5 ms\n",
      "Wall time: 73.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 109 ms\n",
      "Wall time: 14 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = tokenizer([sen] * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast/Slow Tokenizer\n",
    "- FastTokenizer\n",
    "    - 基于Rust实现，速度快\n",
    "    - offset_mapping, word_ids\n",
    "- SlowTokenizer\n",
    "    - 基于python实现，速度慢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"弱小的我也有大 Dreaming！\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer = AutoTokenizer.from_pretrained(\"./roberta_tokenizer/\")\n",
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"./roberta_tokenizer/\", use_fast=False)\n",
    "slow_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 641 ms\n",
      "Wall time: 639 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 单条循环处理\n",
    "for i in range(10000):\n",
    "    fast_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.44 s\n",
      "Wall time: 1.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 单条循环处理\n",
    "for i in range(10000):\n",
    "    slow_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 531 ms\n",
      "Wall time: 215 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 处理batch数据\n",
    "res = fast_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.52 s\n",
      "Wall time: 1.56 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 处理batch数据\n",
    "res = slow_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 10252, 8221, 8013, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (8, 13), (13, 16), (16, 17), (0, 0)]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = fast_tokenizer(sen, return_offsets_mapping=True)\n",
    "# slow_tokenizer不能配置return_offsets_mapping=True\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特殊Tokenizer的加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGLMTokenizer(name_or_path='THUDM/chatglm3-6b', vocab_size=64798, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='left', truncation_side='right', special_tokens={'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t\n",
       "}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"THUDM/chatglm3-6b\", trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('chatglm_tokenizer\\\\tokenizer_config.json',\n",
       " 'chatglm_tokenizer\\\\special_tokens_map.json',\n",
       " 'chatglm_tokenizer\\\\tokenizer.model',\n",
       " 'chatglm_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"chatglm_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mf:\\Code\\MyTransformers\\1-Started\\2-tokenizer\\tokenizer.ipynb 单元格 51\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Code/MyTransformers/1-Started/2-tokenizer/tokenizer.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tokenizer \u001b[39m=\u001b[39m AutoTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(\u001b[39m\"\u001b[39;49m\u001b[39mchatglm_tokenizer\u001b[39;49m\u001b[39m\"\u001b[39;49m, trust_remote_code\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32md:\\work_tools\\Anaconda\\program\\envs\\my_transformers\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:755\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    753\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(pretrained_model_name_or_path):\n\u001b[0;32m    754\u001b[0m         tokenizer_class\u001b[39m.\u001b[39mregister_for_auto_class()\n\u001b[1;32m--> 755\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenizer_class\u001b[39m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[39m*\u001b[39minputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    756\u001b[0m \u001b[39melif\u001b[39;00m config_tokenizer_class \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    757\u001b[0m     tokenizer_class \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32md:\\work_tools\\Anaconda\\program\\envs\\my_transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2024\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2021\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2022\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading file \u001b[39m\u001b[39m{\u001b[39;00mfile_path\u001b[39m}\u001b[39;00m\u001b[39m from cache at \u001b[39m\u001b[39m{\u001b[39;00mresolved_vocab_files[file_id]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 2024\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_from_pretrained(\n\u001b[0;32m   2025\u001b[0m     resolved_vocab_files,\n\u001b[0;32m   2026\u001b[0m     pretrained_model_name_or_path,\n\u001b[0;32m   2027\u001b[0m     init_configuration,\n\u001b[0;32m   2028\u001b[0m     \u001b[39m*\u001b[39minit_inputs,\n\u001b[0;32m   2029\u001b[0m     token\u001b[39m=\u001b[39mtoken,\n\u001b[0;32m   2030\u001b[0m     cache_dir\u001b[39m=\u001b[39mcache_dir,\n\u001b[0;32m   2031\u001b[0m     local_files_only\u001b[39m=\u001b[39mlocal_files_only,\n\u001b[0;32m   2032\u001b[0m     _commit_hash\u001b[39m=\u001b[39mcommit_hash,\n\u001b[0;32m   2033\u001b[0m     _is_local\u001b[39m=\u001b[39mis_local,\n\u001b[0;32m   2034\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   2035\u001b[0m )\n",
      "File \u001b[1;32md:\\work_tools\\Anaconda\\program\\envs\\my_transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2256\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._from_pretrained\u001b[1;34m(cls, resolved_vocab_files, pretrained_model_name_or_path, init_configuration, token, cache_dir, local_files_only, _commit_hash, _is_local, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2254\u001b[0m \u001b[39m# Instantiate the tokenizer.\u001b[39;00m\n\u001b[0;32m   2255\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 2256\u001b[0m     tokenizer \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\u001b[39m*\u001b[39minit_inputs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minit_kwargs)\n\u001b[0;32m   2257\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m   2258\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mOSError\u001b[39;00m(\n\u001b[0;32m   2259\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnable to load vocabulary from file. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2260\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease check that the provided vocabulary is accessible and not corrupted.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2261\u001b[0m     )\n",
      "File \u001b[1;32m~/.cache\\huggingface\\modules\\transformers_modules\\chatglm_tokenizer\\tokenization_chatglm.py:108\u001b[0m, in \u001b[0;36mChatGLMTokenizer.__init__\u001b[1;34m(self, vocab_file, padding_side, clean_up_tokenization_spaces, encode_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mspecial_tokens \u001b[39m=\u001b[39m {\n\u001b[0;32m    103\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<bos>\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mbos_id,\n\u001b[0;32m    104\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<eos>\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39meos_id,\n\u001b[0;32m    105\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<pad>\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpad_id\n\u001b[0;32m    106\u001b[0m }\n\u001b[0;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencode_special_tokens \u001b[39m=\u001b[39m encode_special_tokens\n\u001b[1;32m--> 108\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(padding_side\u001b[39m=\u001b[39mpadding_side, clean_up_tokenization_spaces\u001b[39m=\u001b[39mclean_up_tokenization_spaces,\n\u001b[0;32m    109\u001b[0m                  encode_special_tokens\u001b[39m=\u001b[39mencode_special_tokens,\n\u001b[0;32m    110\u001b[0m                  \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\work_tools\\Anaconda\\program\\envs\\my_transformers\\lib\\site-packages\\transformers\\tokenization_utils.py:363\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_added_tokens_encoder: Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m {k\u001b[39m.\u001b[39mcontent: v \u001b[39mfor\u001b[39;00m v, k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_added_tokens_decoder\u001b[39m.\u001b[39mitems()}\n\u001b[0;32m    362\u001b[0m \u001b[39m# 4 init the parent class\u001b[39;00m\n\u001b[1;32m--> 363\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    365\u001b[0m \u001b[39m# 4. If some of the special tokens are not part of the vocab, we add them, at the end.\u001b[39;00m\n\u001b[0;32m    366\u001b[0m \u001b[39m# the order of addition is the same as self.SPECIAL_TOKENS_ATTRIBUTES following `tokenizers`\u001b[39;00m\n\u001b[0;32m    367\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_add_tokens(\n\u001b[0;32m    368\u001b[0m     [token \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mall_special_tokens_extended \u001b[39mif\u001b[39;00m token \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_added_tokens_encoder],\n\u001b[0;32m    369\u001b[0m     special_tokens\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    370\u001b[0m )\n",
      "File \u001b[1;32md:\\work_tools\\Anaconda\\program\\envs\\my_transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1604\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m   1601\u001b[0m \u001b[39m# Stores a Jinja template that formats chat histories into tokenizable strings\u001b[39;00m\n\u001b[0;32m   1602\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchat_template \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mchat_template\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1604\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\work_tools\\Anaconda\\program\\envs\\my_transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:861\u001b[0m, in \u001b[0;36mSpecialTokensMixin.__init__\u001b[1;34m(self, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    859\u001b[0m     \u001b[39msetattr\u001b[39m(\u001b[39mself\u001b[39m, key, value)\n\u001b[0;32m    860\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, (\u001b[39mstr\u001b[39m, AddedToken)):\n\u001b[1;32m--> 861\u001b[0m     \u001b[39msetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, key, value)\n\u001b[0;32m    862\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSpecial token \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m has to be either str or AddedToken but got: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(value)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"chatglm_tokenizer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[gMASK]sop 弱小的我也有大 Dreaming！'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(sen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_transformers",
   "language": "python",
   "name": "my_transformers"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
